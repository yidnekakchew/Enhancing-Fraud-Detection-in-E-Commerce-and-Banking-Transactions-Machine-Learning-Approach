{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe8FmJPhI1SS",
        "outputId": "b8318c9e-a787-42f3-90fa-64baac51a33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.17.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==2.17.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.17.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (16.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.0->mlflow)\n",
            "  Downloading databricks_sdk-0.35.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.17.0-py3-none-any.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.17.0-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.35.0-py3-none-any.whl (568 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.4/568.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 databricks-sdk-0.35.0 docker-7.1.0 graphene-3.4 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.17.0 mlflow-skinny-2.17.0\n"
          ]
        }
      ],
      "source": [
        "pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MF1GfesGmjV",
        "outputId": "56450f1b-c843-4aeb-fb62-3238a30570c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   user_id          signup_time        purchase_time  purchase_value  \\\n",
              " 0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
              " 1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
              " 2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
              " 3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
              " 4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
              " \n",
              "        device_id source browser sex  age    ip_address  class  \n",
              " 0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0  \n",
              " 1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  \n",
              " 2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  \n",
              " 3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0  \n",
              " 4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0  ,\n",
              "    Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              " 0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              " 1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              " 2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              " 3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              " 4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              " \n",
              "          V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              " 0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              " 1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              " 2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              " 3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              " 4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              " \n",
              "         V26       V27       V28  Amount  Class  \n",
              " 0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              " 1  0.125895 -0.008983  0.014724    2.69      0  \n",
              " 2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              " 3 -0.221929  0.062723  0.061458  123.50      0  \n",
              " 4  0.502292  0.219422  0.215153   69.99      0  \n",
              " \n",
              " [5 rows x 31 columns])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Task 2 - Model Building and Training\n",
        "\n",
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Load datasets from the specified file location\n",
        "fraud_data = pd.read_csv('/content/Fraud_Data.csv')\n",
        "creditcard_data = pd.read_csv('/content/creditcard.csv')\n",
        "\n",
        "# Display the first few rows of each dataset\n",
        "fraud_data.head(), creditcard_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRwyFeNCHDdI"
      },
      "outputs": [],
      "source": [
        "# Data Preparation\n",
        "\n",
        "# Feature and target separation for Fraud Data\n",
        "X_fraud = fraud_data.drop(columns=['class'])\n",
        "y_fraud = fraud_data['class']\n",
        "\n",
        "# Feature and target separation for Credit Card Data\n",
        "X_credit = creditcard_data.drop(columns=['Class'])\n",
        "y_credit = creditcard_data['Class']\n",
        "\n",
        "# Train-Test Split for Fraud Data\n",
        "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(X_fraud, y_fraud, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train-Test Split for Credit Card Data\n",
        "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(X_credit, y_credit, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLf4IwmfJF7C",
        "outputId": "4f679610-7116-44d3-99b5-b8a665709511"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load datasets from the specified file location\n",
        "fraud_data = pd.read_csv('/content/Fraud_Data.csv')\n",
        "creditcard_data = pd.read_csv('/content/creditcard.csv')\n",
        "\n",
        "# Define target variable and feature sets for Fraud Data\n",
        "X_fraud = fraud_data.drop(columns=['class'])  # Adjust as needed based on your DataFrame structure\n",
        "y_fraud = fraud_data['class']\n",
        "\n",
        "# Define target variable and feature sets for Credit Card Data\n",
        "X_credit = creditcard_data.drop(columns=['Class'])  # Adjust as needed based on your DataFrame structure\n",
        "y_credit = creditcard_data['Class']\n",
        "\n",
        "# Split datasets into training and test sets\n",
        "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(X_fraud, y_fraud, test_size=0.2, random_state=42)\n",
        "X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(X_credit, y_credit, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define numerical and categorical columns for fraud data\n",
        "numerical_features_fraud = X_fraud.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "categorical_features_fraud = X_fraud.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Ensure 'user_id' is not in categorical features (if not needed for the model)\n",
        "categorical_features_fraud = [col for col in categorical_features_fraud if col != 'user_id']\n",
        "\n",
        "# Filter features to include only those that exist\n",
        "numerical_features_fraud = [col for col in numerical_features_fraud if col in X_fraud.columns]\n",
        "categorical_features_fraud = [col for col in categorical_features_fraud if col in X_fraud.columns]\n",
        "\n",
        "# Define numerical and categorical columns for credit data\n",
        "numerical_features_credit = X_credit.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "categorical_features_credit = X_credit.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Filter features to include only those that exist\n",
        "numerical_features_credit = [col for col in numerical_features_credit if col in X_credit.columns]\n",
        "categorical_features_credit = [col for col in categorical_features_credit if col in X_credit.columns]\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'Multi-Layer Perceptron (MLP)': MLPClassifier(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Function to train and evaluate models\n",
        "def train_and_evaluate(models, X_train, y_train, X_test, y_test, numerical_features, categorical_features):\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        # Create a pipeline for preprocessing and model fitting\n",
        "        pipeline = Pipeline(steps=[\n",
        "            ('preprocessor', ColumnTransformer(\n",
        "                transformers=[\n",
        "                    ('num', SimpleImputer(strategy='mean'), numerical_features),\n",
        "                    ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features)\n",
        "                ])),\n",
        "            ('classifier', model)\n",
        "        ])\n",
        "\n",
        "        # Fit the model\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = classification_report(y_test, y_pred, output_dict=True)\n",
        "    return results\n",
        "\n",
        "# Train and evaluate models for Fraud Data\n",
        "results_fraud = train_and_evaluate(models, X_fraud_train, y_fraud_train, X_fraud_test, y_fraud_test, numerical_features_fraud, categorical_features_fraud)\n",
        "\n",
        "# Train and evaluate models for Credit Card Data\n",
        "results_credit = train_and_evaluate(models, X_credit_train, y_credit_train, X_credit_test, y_credit_test, numerical_features_credit, categorical_features_credit)\n",
        "\n",
        "# Example of accessing and printing results\n",
        "for model_name, result in results_fraud.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(result['accuracy'])\n",
        "\n",
        "for model_name, result in results_credit.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(result['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bqdktBqOAwD"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC-zuOqBOASV"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation for Fraud Data\n",
        "for name, report in results_fraud.items():\n",
        "    print(f\"Model: {name}\")\n",
        "    print(classification_report(y_test_fraud, report['1']))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Model Evaluation for Credit Card Data\n",
        "for name, report in results_credit.items():\n",
        "    print(f\"Model: {name}\")\n",
        "    print(classification_report(y_test_credit, report['1']))\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpy2ynJxOIio"
      },
      "source": [
        "MLOps Steps - Versioning and Experiment Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XISDOhQ3OIQU"
      },
      "outputs": [],
      "source": [
        "# MLOps Steps - Versioning and Experiment Tracking\n",
        "\n",
        "# Setting up MLflow\n",
        "mlflow.start_run()\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Create a pipeline for preprocessing and model fitting\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', SimpleImputer(strategy='mean'), X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()),\n",
        "                ('cat', OneHotEncoder(drop='first'), X_train.select_dtypes(include=['object']).columns.tolist())\n",
        "            ])),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    # Fit the model\n",
        "    pipeline.fit(X_train_fraud, y_train_fraud)\n",
        "\n",
        "    # Log parameters and model\n",
        "    mlflow.log_param(\"model_name\", name)\n",
        "    mlflow.sklearn.log_model(pipeline, name)\n",
        "\n",
        "mlflow.end_run()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}